{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevendraTomar/llm-learnings/blob/main/GenAI_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "COVRh74O7A9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GenAI Notebook Overview\n",
        "\n",
        "This notebook demonstrates the usage of LangChain for interacting with Large Language Models (LLMs), specifically Google's Gemini and Groq's LLaMa models.\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1. **Introduction to GenAI:**\n",
        "   - Briefly explains the 4 major components of GenAI: Model, Prompt, Output.\n",
        "\n",
        "2. **LangChain Library:**\n",
        "   - Introduces LangChain and its benefits for LLM application development:\n",
        "     - Accelerated Development\n",
        "     - Scalability and Flexibility\n",
        "     - Improved Productivity\n",
        "     - Enhanced User Experiences\n",
        "     - Future-Proof Investments\n",
        "\n",
        "3. **Working with Google Gemini:**\n",
        "   - **Installation:** Installs the `langchain-google-genai` package.\n",
        "   - **Loading Prompt:** Defines a prompt template for translation using `ChatPromptTemplate`.\n",
        "   - **Loading Model:** Initializes a `ChatGoogleGenerativeAI` instance with the Gemini model and API key.\n",
        "   - **Invoking Model:** Sends a prompt for translation and gets the response.\n",
        "   - **Formatting Response:** Uses Pydantic to structure the response into a `Translation` object.\n",
        "   - **Loading into Spark:** Creates a Spark DataFrame from the structured response.\n",
        "   - **Controlling Temperature:** Demonstrates how to adjust the `temperature` parameter for controlling randomness in Gemini's responses.\n",
        "\n",
        "4. **Working with Groq's LLaMa and Tool Calling:**\n",
        "   - **Installation:** Installs the `langchain-groq` package.\n",
        "   - **Loading Model:** Initializes a `ChatGroq` instance with the LLaMa model and API key.\n",
        "   - **External Functions:** Defines a custom tool function using `@tool` decorator.\n",
        "   - **Model with Tools:** Binds the tool function to the LLaMa model using `bind_tools`.\n",
        "   - **Tool Calling:** Demonstrates how to invoke the model with tools and access tool call results.\n",
        "\n",
        "**Key Takeaways:**\n",
        "\n",
        "- LangChain simplifies the development of LLM-powered applications.\n",
        "- It provides a flexible and scalable framework for integrating various LLMs.\n",
        "- Tool calling enables extending LLM capabilities with external functions.\n",
        "- Temperature control allows adjusting the randomness of LLM outputs."
      ],
      "metadata": {
        "id": "ERviV0yJ9af9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GenAI's 4 Major Components:\n",
        "\n",
        "1. **Model:** The core algorithm that powers GenAI, responsible for understanding and generating text.\n",
        "2. **Prompt:** The input given to the model, guiding it to produce the desired output.\n",
        "3. **Output:** The generated text or other content produced by the model"
      ],
      "metadata": {
        "id": "BHuRBOsmmT8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nEfhOblcnCfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Library\n",
        "\n",
        "LangChain is a framework for developing applications powered by large language models (LLMs).\n",
        "\n",
        "| **Benefit**                   | **Description**                                                                                                                                                     |\n",
        "|-------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| **Accelerated Development**    | LangChain abstracts the complexities of integrating and managing LLMs, reducing development time and allowing developers to focus on delivering value-added features. |\n",
        "| **Scalability and Flexibility**| With a modular architecture and support for multiple LLMs, LangChain ensures applications can scale and adapt to evolving language models.                           |\n",
        "| **Improved Productivity**      | By handling LLM integration and memory management, LangChain allows developers to focus on innovative solutions, boosting overall productivity.                      |\n",
        "| **Enhanced User Experiences**  | Enables developers to create sophisticated AI systems and context-aware applications, delivering human-like interactions with AI.                                   |\n",
        "| **Future-Proof Investments**   | LangChain stays up-to-date with the latest advancements in AI and LLMs, ensuring applications remain future-proof and adaptable.                                      |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W0gVz1Vqm0mx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Dependencies"
      ],
      "metadata": {
        "id": "-vQ2qHsbnZio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU  langchain-google-genai\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRSSrwDCpXQz",
        "outputId": "a98e2bea-58b5-4a70-9940-27a2584dc65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Secrets"
      ],
      "metadata": {
        "id": "OSLTnAkl7FKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"]=userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"GROQ_API_KEY\"]=userdata.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "id": "a4xfmGoI7FEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Prompt"
      ],
      "metadata": {
        "id": "Ej7wB3H9s6Kq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6LqDw5iT7EEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_template = \"Translate the following from English into {language}\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
        ")"
      ],
      "metadata": {
        "id": "B-u2AeccpbGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Model"
      ],
      "metadata": {
        "id": "9NIopPqws5GQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1-FHg5eEukWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure your VertexAI credentials are configured\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-pro-exp-02-05\")\n"
      ],
      "metadata": {
        "id": "EX8M62QBtB1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=llm.invoke(prompt_template.format_prompt(language=\"French\", text=\"I love programming.\"))"
      ],
      "metadata": {
        "id": "_Wwv1Z04w_Z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "gOlWGWb-xIsg",
        "outputId": "9193972d-eb7d-4757-fb71-e57f511d072e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The most straightforward and common translation is:\\n\\n**J\\'aime programmer.**\\n\\nHere are a few other options, with slightly different nuances:\\n\\n*   **J\\'adore programmer.** (This emphasizes a stronger feeling, like \"I really love programming.\")\\n*   **J\\'aime la programmation.** (This is more formal and refers to programming as a general concept/field.)\\n*    **J\\'aime faire de la programmation** (I like to do programming)\\n\\nThe best option depends on the specific context, but \"J\\'aime programmer\" is generally the most suitable.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Formatting Response Leveraging Pypdantic Class"
      ],
      "metadata": {
        "id": "5k1Otyxuw9xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Create a pydantic model to have 2 columns english: original sentence passed and translated text\n",
        "\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class Translation(BaseModel):\n",
        "    english: str\n",
        "    translated: str\n"
      ],
      "metadata": {
        "id": "lc3x6DwZxl5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str_resp=llm.with_structured_output(schema=Translation).invoke(prompt_template.format_prompt(language=\"French\", text=\"I love programming.\"))"
      ],
      "metadata": {
        "id": "z0lCrQxPxnqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str_resp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVSH10oeyCIR",
        "outputId": "da250320-ca96-4ca0-c154-7361fd760fbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Translation(english='I love programming.', translated=\"J'adore programmer\")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading into Spark"
      ],
      "metadata": {
        "id": "p-GaoWC3zXfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "y4sli186yER7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "xqKxQEedzJ7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.createDataFrame([str_resp],schema=\"english string, translated string\")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ijmFzxyzeXp",
        "outputId": "2046fe62-101e-4c33-f29b-62afe5161986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------------------+\n",
            "|            english|        translated|\n",
            "+-------------------+------------------+\n",
            "|I love programming.|J'adore programmer|\n",
            "+-------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z_QrYNM10c8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure your VertexAI credentials are configured\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-pro-exp-02-05\",temperature=0)\n"
      ],
      "metadata": {
        "id": "sn5c_Et10ckB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"who is MS Dhoni? respond in not more than 50 words\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1Zkz5ww0f_2",
        "outputId": "d3ccf2da-46c7-4af9-bde3-b28b6b9d5bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Mahendra Singh Dhoni (MS Dhoni) is a former Indian international cricketer and captain. Known for his calm demeanor and exceptional wicket-keeping skills, he's considered one of the greatest captains and finishers in the history of the sport, leading India to victory in all three major ICC trophies.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-37e59943-4ba7-48e2-ae52-3f1b0ae58f08-0', usage_metadata={'input_tokens': 15, 'output_tokens': 59, 'total_tokens': 74, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"who is MS Dhoni? respond in not more than 50 words\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyrXYA340qB4",
        "outputId": "43baea21-8e30-4dcf-9eae-b7c95e7c735b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Mahendra Singh Dhoni (MS Dhoni) is a former Indian international cricketer and captain. Known for his calm demeanor and exceptional wicket-keeping skills, he's considered one of the greatest captains and finishers in the history of the sport, leading India to victory in all three major ICC trophies.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-a2afc1d0-eae1-4a2d-bf9c-41887e10b247-0', usage_metadata={'input_tokens': 15, 'output_tokens': 59, 'total_tokens': 74, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Change Temperature to higher value for more randomNess"
      ],
      "metadata": {
        "id": "cnWYD6tn1qpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure your VertexAI credentials are configured\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-pro-exp-02-05\",temperature=1)\n"
      ],
      "metadata": {
        "id": "3Cw0jIZd0tHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"who is MS Dhoni? respond in not more than 50 words\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2DvVA-20xxl",
        "outputId": "b28e7fa7-41a2-4e19-b431-621b2314f8b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Mahendra Singh Dhoni (MS Dhoni) is a former Indian international cricketer and captain. Known for his calm demeanor and exceptional wicket-keeping skills, he's considered one of the greatest captains and finishers in limited-overs cricket, leading India to victory in all three major ICC trophies.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-ae3cf809-9018-4362-9854-abef06df6071-0', usage_metadata={'input_tokens': 15, 'output_tokens': 58, 'total_tokens': 73, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"who is MS Dhoni? respond in not more than 50 words\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l9k54of0zww",
        "outputId": "26038d30-4177-4e4c-f8fe-fb477050c938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Mahendra Singh Dhoni (MS Dhoni) is a former Indian international cricketer and captain. Known for his calm demeanor and exceptional wicket-keeping skills, he's considered one of the greatest captains and finishers in cricket history, leading India to multiple major ICC tournament victories.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-b8c9b124-ec22-42b7-aa5a-faaa0a9a2852-0', usage_metadata={'input_tokens': 15, 'output_tokens': 54, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Use External Functions with Tool Calling"
      ],
      "metadata": {
        "id": "-ebhBrbe1deU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply a and b.\"\"\"\n",
        "    return a * b"
      ],
      "metadata": {
        "id": "VarLMZBk2WSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chaning Model with 2 clicks using Langchain"
      ],
      "metadata": {
        "id": "3PjQgjk6332l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-groq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp5Lpuqs313D",
        "outputId": "d65553f3-0c37-42c4-dbb5-53ee7253e67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.2.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain-groq)\n",
            "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.3.35)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (0.3.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (24.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (2.3.0)\n",
            "Downloading langchain_groq-0.2.4-py3-none-any.whl (14 kB)\n",
            "Downloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-groq\n",
            "Successfully installed groq-0.18.0 langchain-groq-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure your VertexAI credentials are configured\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(model=\"llama-3.3-70b-versatile\",temperature=0)\n"
      ],
      "metadata": {
        "id": "Gk0y2i7P3-kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"what is 2*3 and then multiplied by 100\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5b16vKH4XRp",
        "outputId": "a7d20e59-ecd5-4a77-d40e-b1035fa2c20d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='To calculate this, we need to follow the order of operations (PEMDAS):\\n\\n1. Multiply 2 and 3: 2 * 3 = 6\\n2. Multiply 6 by 100: 6 * 100 = 600\\n\\nSo the final answer is 600.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 47, 'total_tokens': 109, 'completion_time': 0.225454545, 'prompt_time': 0.005015091, 'queue_time': 0.834260455, 'total_time': 0.230469636}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_e669a124b2', 'finish_reason': 'stop', 'logprobs': None}, id='run-adf24485-0883-420d-8ceb-5b03d1047abd-0', usage_metadata={'input_tokens': 47, 'output_tokens': 62, 'total_tokens': 109})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tools=llm.bind_tools([multiply])"
      ],
      "metadata": {
        "id": "jL2ESOI65HHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp=llm_with_tools.invoke(\"what is 2*3 \")"
      ],
      "metadata": {
        "id": "aZWI8ojV5Xbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp.tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scvpy3B_7mOp",
        "outputId": "58da0cfb-951a-4912-f47f-940cd5d97675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'multiply',\n",
              "  'args': {'a': 2, 'b': 3},\n",
              "  'id': 'call_8fb9',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiply.invoke(input=resp.tool_calls[0].get(\"args\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGdPtGGG5ckV",
        "outputId": "5aa42c40-3645-449b-e071-82714733254f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp=llm_with_tools.invoke(\"what is 2*3 and then multiplied by 100\")"
      ],
      "metadata": {
        "id": "9rBkEOPs6O0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cztis-uw8--Y",
        "outputId": "1b13771e-902c-4073-9498-58360c602c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_rpd7', 'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_g4e6', 'function': {'arguments': '{\"a\": 6, \"b\": 100}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 226, 'total_tokens': 263, 'completion_time': 0.134545455, 'prompt_time': 0.01579244, 'queue_time': 0.514418023, 'total_time': 0.150337895}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_5f849c5a0b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3cd57629-affd-4852-9b15-5001995f8052-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_rpd7', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 6, 'b': 100}, 'id': 'call_g4e6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 226, 'output_tokens': 37, 'total_tokens': 263})"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp.tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h3N3T5p8xEP",
        "outputId": "46d23d43-2b9f-402f-c9c0-1e454d8b303c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'multiply',\n",
              "  'args': {'a': 2, 'b': 3},\n",
              "  'id': 'call_rpd7',\n",
              "  'type': 'tool_call'},\n",
              " {'name': 'multiply',\n",
              "  'args': {'a': 6, 'b': 100},\n",
              "  'id': 'call_g4e6',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iD6rb_Ch8zYE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}